2025年3月6日
16点15分
javafx

2025年3月7日
09点43分
研究github实现两台电脑同步javafx项目
10点42分

12点41分
研究github同步笔记
14点48分

19点49分
完善javafx音乐播放器
23点05分

2025年3月8日
20点45分
重构javafx音乐播放器
实现主页面布局
基础音乐播放功能
完蛋 还是要MVC架构
22点58分

2025年3月11日
15点22分
研究水论文
“”“心态崩了”“”
16点33分

2025年3月12日
15点20分
看VIT论文
17点38分

2025年3月15日
17点39分
研究apple外区账号
放弃 等以后换了手机再说
17点43分

2025年3月16日
11点45分
追番软件kuzumi
悠哉日常大王
睡觉
16点25分

2025年3月17日 星期一
09点57分
看vit论文精读 [[vit论文笔记]]
吃饭
看MAE论文精读 [[MAE]]
复现vit的patch模块
https://www.bilibili.com/video/BV1Xwc6eoEBa?spm_id_from=333.788.player.switch&vd_source=d70de14647568dd4288a34970c7b2440

15点01分
attention模块不理解 -> 李沐transformer论文精读 [[Transformer]] -> 李宏毅讲解
https://www.bilibili.com/video/BV1v3411r78R/?spm_id_from=333.337.search-card.all.click&vd_source=d70de14647568dd4288a34970c7b2440
基本明白了注意力机制和多头注意力机制的计算过程
后面要做的
- 看完注意力机制和transformer论文讲解
- 输出相应的学习笔记
- 复现vit代码 
16点41分

2025年3月18日
13点54分
李宏毅和李沐 transformer讲解
最关键的一个点 在于
transformer的encoder和decoder的注意力模块的输入和输出分别是什么

encoder
输入是 单词 -> token -> wordembeding
输出是 wordembeding -> slef-attention ->wordembeding

decoder
输入1是 初始token -> wordembeding
输出是 wordembeding -> wordembeding
输入2是encoder的 wordembeding 和输入1的 wordembeding
而且wordembeding作为q encode的 wordembeding作为kv
16点10分

2025年3月19日
09点38分
复现 vit模型 中的 
10点23分

2025年3月20日
10点23分
vit复现


2025年3月21日
09点34分
复现vit的mlp模块
复现完整的vit模块
11点28分

2025年3月22日
15点14分
复现了完整的vit模型
但是对于训练流程有点遗忘了
下一个目标 搭建深度学习知识库 包含常见 模型 训练过程 各种模块 参数 方法的使用
16点35分

16点35分
整理vit模型笔记
[[Vision Transformer - Base]]


2025年3月23日
16点04分
整理论文思路 [[乳腺癌+深度学习 分类]]

2025年3月25日
20点10分6
做实验 实验记录[[乳腺癌+深度学习 分类]]
目前cnn融合vit特征 + 交叉注意力 + mlp
应该是可行的 
后续计划是调参(修改模型结果) + GAN生成更多的样本
23点59分6


