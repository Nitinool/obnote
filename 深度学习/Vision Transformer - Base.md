[[Transformer]]


可以改进的点
1. 更换最开始tokenizition
2. 更换transformer block里面的self attention 换成mlp


###### Vit-base模型结构 参数量86M

| 层                     | 输入               | 输出            |                           | 参数量        |
| --------------------- | ---------------- | ------------- | ------------------------- | ---------- |
| Input Image           | [B, 3, 224, 224] |               |                           |            |
| Patch Embedding       | [B, 3, 224, 224] | [B, 196, 768] | 16x16卷积切割                 | 589,824    |
| [CLS] Token添加         | [B, 196, 768]    | [B, 197, 768] | 拼接CLS向量                   | 768        |
| 位置编码                  | [B, 197, 768]    | [B, 197, 768] | 元素相加                      | 151,296    |
| Transformer Block ×12 | [B, 197, 768]    | [B, 197, 768] | 注意力→MLP→残差连接              | 77,844,480 |
| 最终LayerNorm           | [B, 197, 768]    | [B, 197, 768] | 层归一化                      | 1,536      |
| 提取CLS Token           | [B, 197, 768]    | [B, 768]      | 取第一个位置                    |            |
| 分类头                   | [B, 768]         | [B, 1000]     | 全连接层映射 <br>1000对应1000分类任务 | 769,000    |
|                       |                  |               |                           | 86,567,904 |
